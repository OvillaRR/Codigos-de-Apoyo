{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c39cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# 1. INSTALAR LIBRERÍA\n",
    "# pip install tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9ba6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Faker para generar datos en español\n",
    "fake = Faker('es_MX')\n",
    "\n",
    "\n",
    "# Listas de conceptos clave, ahora más extensas\n",
    "keywords_retiro = [\n",
    "    \"PAGO\", \"COMPRA\", \"COMISION\", \"RETIRO\", \"CARGO\", \"CARGO POR \" , \"TRANSFERENCIA A\", \n",
    "    \"CHEQUE PAGADO\", \"IVA\", \"SPEI ENVIADO\", \"PAGO CUENTA DE TERCERO\", \n",
    "    \"DOMICILIACION\", \"CARGO AUTOMATICO\", \"TRASPASO A CUENTA\" , \" RETIRO SIN\" , \"DISPOCISION DE\" , \n",
    "    \"PAGO INTERBANCARIO\" , \n",
    "]\n",
    "\n",
    "keywords_deposito = [\n",
    "    \"DEPOSITO\", \"ABONO\", \"NOMINA\", \"SPEI RECIBIDO\", \"TRANSFERENCIA DE\", \n",
    "    \"PAGO DE\", \"REEMBOLSO\", \"TRASPASO DE CUENTA\", \"A SU FAVOR\", \"PAGO RECIBIDO\" , \n",
    "    \"DEVOLUCION\", \"ABONO INVERSION\", \"PAGO INTERESES\" , \"TRASPASO ENTRE CUENTAS\" , \" TRASP ENTRE CUENTAS\" , \"ABONO POR DEVOLUCION\" , \n",
    "    \"TRANS ENTRE CTAS\" , \"DISPOCICION DE EFECTIVO\"\n",
    "]\n",
    "\n",
    "# Listas de entidades específicas para más realismo\n",
    "bancos = [\"BANAMEX\", \"BBVA\", \"SANTANDER\", \"SCOTIABANK\", \"HSBC\", \"BANORTE\", \"STP\", \"BANCOPPEL\", \"AZTECA\" , \"NU BANK\" , \n",
    "          \"BANREGIO\" , \"BANJERCITO\" , \"INBURSA\" , \"BANK OF AMERICA\" , \"NAFIN\" , \"BANK OF CHINA\" , \"ZURICH\"\n",
    "          ] \n",
    "\n",
    "merchants = [\"AMAZON MX\", \"MERCADOLIBRE\", \"NETFLIX\", \"SPOTIFY\", \"UBER EATS\", \"WALMART\", \"LIVERPOOL\", \"STEAM\" , \"OXXO\" , \n",
    "             \"BODEGA AURRERA\" , \"SEARS\" , \"AUTOZONE\" , \"SCOTIACARD\" , \"DIDI\" , \"PIZZA HOT\"\n",
    "             \n",
    "             ]\n",
    "\n",
    "payment_processors = [\"ADYENMX\", \"MP ECOMMERCE\", \"PAYPAL\", \"CONEKTA\", \"STRIPE\"]\n",
    "\n",
    "tipos_inversion = [\"PAGARE\", \"FONDO DE INVERSION\", \"CETES\", \"ACCIONES\", \"PRLV\" , \"FINTUAL\" , \"INVERSION\"]\n",
    "\n",
    "\n",
    "# Modificamos la función para que sea más fácil inyectar ruido\n",
    "def generar_transaccion_sintetica_ruidosa():\n",
    "    # --- Generación de la descripción base (lógica similar a la anterior) ---\n",
    "    if random.random() > 0.45:\n",
    "        tipo = 'retiro'\n",
    "        plantillas = [\n",
    "            \"PAGO SERVICIOS {empresa} REF#{ref_num}\", \"COMPRA EN {merchant}\", \"{processor}*{merchant}\",\n",
    "            \"TRANSFERENCIA A {persona}\", \" SWEB TRANSFERENCIA A {persona}\" ,\"SPEI ENVIADO {banco}\", \"PAGO CUENTA TERCERO\",\n",
    "            \"TRASPASO A CUENTA CLABE {clabe}\", \"INVERSION EN {tipo_inversion}\", \"RETIRO CAJERO {banco}\"\n",
    "        ]\n",
    "        # ... (lógica de format para retiros)\n",
    "        descripcion = random.choice(plantillas).format(\n",
    "            empresa=fake.company(), merchant=random.choice(merchants), processor=random.choice(payment_processors),\n",
    "            persona=fake.name(), banco=random.choice(bancos), clabe=fake.numerify('##################'),\n",
    "            tipo_inversion=random.choice(tipos_inversion), ref=fake.bothify(text='??-####'),\n",
    "            ref_num=fake.random_number(digits=8)\n",
    "        )\n",
    "    else:\n",
    "        tipo = 'deposito'\n",
    "        plantillas = [\n",
    "            \"DEPOSITO DE {persona}\", \"ABONO NOMINA {empresa}\", \"TRANSFERENCIA SPEI A SU FAVOR\",\n",
    "            \"SPEI RECIBIDO DE {banco}\", \"TRANSFERENCIA DE\", \"PAGO DE {empresa}\", \"REEMBOLSO {merchant}\",\n",
    "            \"ABONO TRASPASO DE CUENTA\", \"VENCIMIENTO INVERSION {tipo_inversion}\", \"DEPOSITO EN EFECTIVO\" , \"TRASPASO ENTRE CUENTAS\"\n",
    "        ]\n",
    "        # ... (lógica de format para depósitos)\n",
    "        descripcion = random.choice(plantillas).format(\n",
    "            persona=fake.name(), empresa=fake.company(), banco=random.choice(bancos),\n",
    "            merchant=random.choice(merchants), tipo_inversion=random.choice(tipos_inversion)\n",
    "        )\n",
    "    \n",
    "    descripcion = descripcion.lower()\n",
    "\n",
    "    # --- INYECCIÓN DE RUIDO (La parte nueva y clave) ---\n",
    "    # Aplicar ruido a un 60% de las muestras\n",
    "    if random.random() < 0.6:\n",
    "        palabras = descripcion.split()\n",
    "        \n",
    "        # 1. Pegar palabras aleatoriamente\n",
    "        if len(palabras) > 1 and random.random() < 0.5:\n",
    "            idx = random.randint(0, len(palabras) - 2)\n",
    "            palabras[idx] = palabras[idx] + palabras[idx+1]\n",
    "            del palabras[idx+1]\n",
    "        \n",
    "        # 2. Añadir códigos numéricos al inicio o final\n",
    "        if random.random() < 0.4:\n",
    "            palabras.insert(0, fake.numerify('########'))\n",
    "        if random.random() < 0.4:\n",
    "            palabras.append(fake.numerify('############'))\n",
    "            \n",
    "        # 3. Añadir un monto en medio o al final\n",
    "        if random.random() < 0.3:\n",
    "            monto = f\"{random.randint(1, 50)},{random.randint(100, 999):03d}.{random.randint(0,99):02d}\"\n",
    "            pos = random.randint(1, len(palabras))\n",
    "            palabras.insert(pos, monto)\n",
    "            \n",
    "        descripcion = \" \".join(palabras)\n",
    "\n",
    "    # El resto de la función es igual\n",
    "    case_style = random.choice(['original', 'upper'])\n",
    "    if case_style == 'upper':\n",
    "        return descripcion.upper(), tipo\n",
    "    else:\n",
    "        return descripcion, tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "787e8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Normaliza el texto para el modelo:\n",
    "    1. Convierte a minúsculas.\n",
    "    2. Reemplaza cualquier número (entero, decimal, con comas) por un token especial <NUM>.\n",
    "    3. Elimina espacios extra.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    # Regex para encontrar cualquier secuencia de dígitos, que puede incluir comas y puntos.\n",
    "    text = re.sub(r'\\d[\\d,.]*\\d|\\d', '<NUM>', text)\n",
    "    # Reemplazar múltiples espacios con uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "821bcb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parte 2: Función de Pre-procesamiento ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d[\\d,.]*\\d|\\d', '<NUM>', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Generar y pre-procesar datos\n",
    "num_muestras = 30000\n",
    "df = pd.DataFrame([generar_transaccion_sintetica_ruidosa() for _ in range(num_muestras)], columns=['Descripcion', 'Tipo'])\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Tipo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4a0e6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15445</th>\n",
       "      <td>sweb transferencia a natividad orozco munguía</td>\n",
       "      <td>retiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18924</th>\n",
       "      <td>ABONO TRASPASO DE CUENTA</td>\n",
       "      <td>deposito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24803</th>\n",
       "      <td>traspaso a cuenta clabe 075166089621024600</td>\n",
       "      <td>retiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16237</th>\n",
       "      <td>TRASPASO A CUENTA CLABE 568953275297774442 441...</td>\n",
       "      <td>retiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22328</th>\n",
       "      <td>pago de despacho benítez, trejo y rubio</td>\n",
       "      <td>deposito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9800</th>\n",
       "      <td>vencimiento inversion prlv</td>\n",
       "      <td>deposito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13259</th>\n",
       "      <td>spei enviado stp</td>\n",
       "      <td>retiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>deposito en efectivo</td>\n",
       "      <td>deposito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>TRASPASO A CUENTA CLABE865816890904670793 0829...</td>\n",
       "      <td>retiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>PAGO SERVICIOS CORPORACIN GALLARDO, ÁVALOS Y C...</td>\n",
       "      <td>retiro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Descripcion      Tipo\n",
       "15445      sweb transferencia a natividad orozco munguía    retiro\n",
       "18924                           ABONO TRASPASO DE CUENTA  deposito\n",
       "24803         traspaso a cuenta clabe 075166089621024600    retiro\n",
       "16237  TRASPASO A CUENTA CLABE 568953275297774442 441...    retiro\n",
       "22328            pago de despacho benítez, trejo y rubio  deposito\n",
       "9800                          vencimiento inversion prlv  deposito\n",
       "13259                                   spei enviado stp    retiro\n",
       "6859                                deposito en efectivo  deposito\n",
       "2539   TRASPASO A CUENTA CLABE865816890904670793 0829...    retiro\n",
       "4573   PAGO SERVICIOS CORPORACIN GALLARDO, ÁVALOS Y C...    retiro"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a3992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando tokenizador existente.\n"
     ]
    }
   ],
   "source": [
    "# --- Parte 3: Tokenizador entrenado con datos pre-procesados ---\n",
    "TOKENIZER_FILE = \"noisy_transaction_tokenizer.json\"\n",
    "if not os.path.exists(TOKENIZER_FILE):\n",
    "    print(\"Entrenando un nuevo tokenizador en datos ruidosos y pre-procesados...\")\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    # ¡IMPORTANTE! El tokenizador debe aprender el token <NUM>\n",
    "    trainer = BpeTrainer(special_tokens=[\"<unk>\", \"<pad>\", \"<NUM>\"], vocab_size=2000)\n",
    "    # ¡IMPORTANTE! Entrenamos el tokenizador sobre el texto ya pre-procesado\n",
    "    train_iterator = (preprocess_text(text) for text in train_df['Descripcion'])\n",
    "    tokenizer.train_from_iterator(train_iterator, trainer=trainer)\n",
    "    tokenizer.save(TOKENIZER_FILE)\n",
    "else:\n",
    "    print(\"Cargando tokenizador existente.\")\n",
    "tokenizer = Tokenizer.from_file(TOKENIZER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55b8f64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Probando el pipeline de procesamiento completo ---\n",
      "Original: 'Pago CUENTAde tercero'\n",
      "Pre-procesado: 'pago cuentade tercero'\n",
      "Tokens: ['pago', 'cuenta', 'de', 'tercero']\n"
     ]
    }
   ],
   "source": [
    "# --- PRUEBA del pipeline de procesamiento ---\n",
    "print(\"\\n--- Probando el pipeline de procesamiento completo ---\")\n",
    "original_phrase = 'Pago CUENTAde tercero'\n",
    "preprocessed_phrase = preprocess_text(original_phrase)\n",
    "encoding = tokenizer.encode(preprocessed_phrase)\n",
    "print(f\"Original: '{original_phrase}'\")\n",
    "print(f\"Pre-procesado: '{preprocessed_phrase}'\")\n",
    "print(f\"Tokens: {encoding.tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d89969e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta es la versión CORRECTA y ACTUALIZADA\n",
    "class NoisyTransactionDataset(Dataset):\n",
    "    # 1. Ahora recibe la función \"preprocessor\" en el constructor\n",
    "    def __init__(self, dataframe, tokenizer, label_map, preprocessor):\n",
    "        self.df = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_map = label_map\n",
    "        self.preprocessor = preprocessor # La guardamos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 2. Toma el texto crudo\n",
    "        text = self.df.iloc[idx]['Descripcion']\n",
    "        label_str = self.df.iloc[idx]['Tipo']\n",
    "        label = self.label_map[label_str]\n",
    "        \n",
    "        # 3. ¡PASO CLAVE! Aplica la limpieza ANTES de tokenizar\n",
    "        preprocessed_text = self.preprocessor(text)\n",
    "        \n",
    "        # 4. Tokeniza el texto ya limpio y normalizado\n",
    "        token_ids = self.tokenizer.encode(preprocessed_text).ids\n",
    "        \n",
    "        return torch.tensor(token_ids), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b1cf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'retiro': 0, 'deposito': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "920787b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(_label)\n",
    "        text_list.append(_text)\n",
    "    pad_token_id = tokenizer.token_to_id(\"<pad>\")\n",
    "    text_padded = pad_sequence(text_list, batch_first=True, padding_value=pad_token_id)\n",
    "    return text_padded, torch.tensor(label_list, dtype=torch.long)\n",
    "\n",
    "# 4.3. Instanciación del Dataset y DataLoader\n",
    "train_dataset = NoisyTransactionDataset(train_df, tokenizer, label_map, preprocess_text)\n",
    "test_dataset = NoisyTransactionDataset(test_df, tokenizer, label_map, preprocess_text)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c81bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, \n",
    "                            bidirectional=True, batch_first=True, dropout=0.3)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# 4.5. Instanciación del modelo y componentes de entrenamiento\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 2\n",
    "PAD_IDX = tokenizer.token_to_id(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77f7862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Entrenamiento Final ---\n",
      "Epoch 01, Loss: 0.1135\n",
      "Epoch 02, Loss: 0.0124\n",
      "Epoch 03, Loss: 0.0076\n",
      "Epoch 04, Loss: 0.0075\n",
      "Epoch 05, Loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMClassifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, PAD_IDX)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- Parte 5: Bucle de Entrenamiento (formato multi-línea) ---\n",
    "print(\"\\n--- Iniciando Entrenamiento---\")\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for texts, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch+1:02}, Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6a3af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_transaction_final(text, modelo, tokenizer, preprocessor, device='cpu'):\n",
    "    \"\"\"\n",
    "    Función completa para predecir una sola transacción de texto.\n",
    "    \"\"\"\n",
    "    modelo.eval()\n",
    "    modelo.to(device)\n",
    "    \n",
    "    # Aplicar el mismo pre-procesamiento que en el entrenamiento\n",
    "    preprocessed_text = preprocessor(text)\n",
    "    \n",
    "    # Usar el tokenizador para procesar el texto de entrada\n",
    "    token_ids = tokenizer.encode(preprocessed_text).ids\n",
    "    \n",
    "    # Convertir a tensor y añadir una dimensión de \"batch\" (tamaño 1)\n",
    "    tensor = torch.LongTensor(token_ids).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Realizar la predicción\n",
    "    prediction = modelo(tensor)\n",
    "    \n",
    "    # Obtener el índice de la clase con mayor probabilidad\n",
    "    _, predicted_idx = torch.max(prediction.data, 1)\n",
    "    \n",
    "    # Devolver el nombre de la clase\n",
    "    inv_label_map = {v: k for k, v in label_map.items()}\n",
    "    return inv_label_map[predicted_idx.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b188e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_de_prueba = [\n",
    "    \"spei recibidobanregio 14,5600 245345234523454\",\n",
    "    \"Pago cuenta de tercero 3,016.00 00080009000 \" , \n",
    "    \" abr retiro cajero automatico sb $3,000.00 $25,00.00 scotiabank san isidro mx ref 132413243 123412341234\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "695ae3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto Original: 'spei recibidobanregio 14,5600 245345234523454'\n",
      "   ↳ Predicción: DEPOSITO\n",
      "\n",
      "Texto Original: 'Pago cuenta de tercero 3,016.00 00080009000 '\n",
      "   ↳ Predicción: DEPOSITO\n",
      "\n",
      "Texto Original: ' abr retiro cajero automatico sb $3,000.00 $25,00.00 scotiabank san isidro mx ref 132413243 123412341234'\n",
      "   ↳ Predicción: RETIRO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for texto in textos_de_prueba:\n",
    "    # Llama a la función de predicción\n",
    "    prediccion = predict_transaction_final(texto, model, tokenizer, preprocess_text)\n",
    "    \n",
    "    # Imprime el resultado de forma clara\n",
    "    print(f\"Texto Original: '{texto}'\")\n",
    "    print(f\"   ↳ Predicción: {prediccion.upper()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087b720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
